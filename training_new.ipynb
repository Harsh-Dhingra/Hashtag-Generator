{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kax8pCA3aTjI","executionInfo":{"status":"ok","timestamp":1692022709240,"user_tz":-330,"elapsed":22881,"user":{"displayName":"DS With Reddy","userId":"04914551767688149617"}},"outputId":"e20a8183-9b91-4946-85c7-b2639c9e4ddc"},"id":"Kax8pCA3aTjI","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"id":"407cbc68","metadata":{"id":"407cbc68","executionInfo":{"status":"ok","timestamp":1692022713789,"user_tz":-330,"elapsed":466,"user":{"displayName":"DS With Reddy","userId":"04914551767688149617"}}},"outputs":[],"source":["import tensorflow as tf\n","import random\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","# Set the path to the dataset directory\n","dataset_path = \"sort_sports/\"\n","\n","# Set the image dimensions and batch size\n","img_height, img_width = 150, 150\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"id":"2f01cea5","metadata":{"id":"2f01cea5","outputId":"6ee4aa6f-d529-4fc4-e023-9b2fe76ab227","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692017482145,"user_tz":-60,"elapsed":4,"user":{"displayName":"Monty","userId":"07150733663618671138"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 0 images belonging to 1 classes.\n","Found 0 images belonging to 1 classes.\n"]}],"source":["# Data preprocessing and augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    dataset_path,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    dataset_path,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='validation'\n",")"]},{"cell_type":"code","execution_count":null,"id":"f5c8d114","metadata":{"id":"f5c8d114","outputId":"985a62ec-744b-49d6-ef55-5acb53307b87","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"error","timestamp":1692017482487,"user_tz":-60,"elapsed":345,"user":{"displayName":"Monty","userId":"07150733663618671138"}}},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-0c1079ed9785>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                   metrics=['accuracy'])\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m history = model_cnn.fit(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;34m\"Asked to retrieve element {idx}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;34m\"but the Sequence \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"]}],"source":["# Build and train the CNN model\n","model_cnn = keras.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(5, activation='softmax')\n","])\n","\n","model_cnn.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","history = model_cnn.fit(\n","    train_generator,\n","    validation_data=validation_generator,\n","    epochs=10\n",")"]},{"cell_type":"code","execution_count":null,"id":"b5d5fa49","metadata":{"id":"b5d5fa49"},"outputs":[],"source":["# Get the training and validation accuracy values from the history object\n","train_accuracy = history.history['accuracy']\n","val_accuracy = history.history['val_accuracy']\n","\n","# Plot the training and validation accuracy curves\n","epochs = range(1, len(train_accuracy) + 1)\n","\n","plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n","\n","plt.title('Training and Validation Accuracy for CNN')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"062fd4d4","metadata":{"id":"062fd4d4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9353aad0","metadata":{"id":"9353aad0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"3f366698","metadata":{"id":"3f366698"},"outputs":[],"source":["# Apply transfer learning using pre-trained model\n","base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),\n","                                               include_top=False,\n","                                               weights='imagenet')\n","\n","base_model.trainable = False\n","\n","model_transfer_learning = keras.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(5, activation='softmax')\n","])\n","\n","model_transfer_learning.compile(optimizer='adam',\n","                                loss='categorical_crossentropy',\n","                                metrics=['accuracy'])\n","\n","history_tf = model_transfer_learning.fit(\n","    train_generator,\n","    validation_data=validation_generator,\n","    epochs=10\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"4d68d015","metadata":{"id":"4d68d015"},"outputs":[],"source":["# Get the training and validation accuracy values from the history object\n","train_accuracy = history_tf.history['accuracy']\n","val_accuracy = history_tf.history['val_accuracy']\n","\n","# Plot the training and validation accuracy curves\n","epochs = range(1, len(train_accuracy) + 1)\n","\n","plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n","\n","plt.title('Training and Validation Accuracy for Transfer Learning')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"76a80413","metadata":{"id":"76a80413"},"outputs":[],"source":["# Saving the trained model\n","model_transfer_learning.save('trained_model.h5')\n","model_cnn.save('cnn_trained_model.h5')"]},{"cell_type":"code","execution_count":null,"id":"92020aa9","metadata":{"id":"92020aa9"},"outputs":[],"source":["# Evaluate the models\n","cnn_loss, cnn_accuracy = model_cnn.evaluate(validation_generator)\n","transfer_loss, transfer_accuracy = model_transfer_learning.evaluate(validation_generator)\n","\n","print(\"CNN Model - Loss:\", cnn_loss, \"Accuracy:\", cnn_accuracy)\n","print(\"Transfer Learning Model - Loss:\", transfer_loss, \"Accuracy:\", transfer_accuracy)"]},{"cell_type":"code","execution_count":null,"id":"495c7c00","metadata":{"id":"495c7c00"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.preprocessing import image\n","\n","# Load and preprocess the test image\n","test_image_path = \"sort_sports/2023-07-03_04-16-29_UTC.jpg\"\n","test_image = image.load_img(test_image_path, target_size=(img_height, img_width))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis=0)\n","test_image /= 255.0"]},{"cell_type":"code","execution_count":null,"id":"562dd02e","metadata":{"id":"562dd02e"},"outputs":[],"source":["# Make predictions using the CNN model\n","cnn_predictions = model_cnn.predict(test_image)\n","cnn_predicted_class = np.argmax(cnn_predictions)\n","cnn_class_labels = train_generator.class_indices\n","cnn_predicted_label = list(cnn_class_labels.keys())[list(cnn_class_labels.values()).index(cnn_predicted_class)]\n","\n","# Make predictions using the transfer learning model\n","transfer_predictions = model_transfer_learning.predict(test_image)\n","transfer_predicted_class = np.argmax(transfer_predictions)\n","transfer_class_labels = train_generator.class_indices\n","transfer_predicted_label = list(transfer_class_labels.keys())[list(transfer_class_labels.values()).index(transfer_predicted_class)]"]},{"cell_type":"code","execution_count":null,"id":"10d22021","metadata":{"id":"10d22021"},"outputs":[],"source":["# Print the predictions\n","print(\"CNN Predicted Label:\", cnn_predicted_label)\n","print(\"Transfer Learning Predicted Label:\", transfer_predicted_label)"]},{"cell_type":"code","execution_count":null,"id":"a75dbea0","metadata":{"id":"a75dbea0"},"outputs":[],"source":["import json\n","\n","with open('tags.json', 'r') as json_file:\n","    hashtags_mapping = json.load(json_file)"]},{"cell_type":"code","execution_count":null,"id":"091f4d7c","metadata":{"id":"091f4d7c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"be5e67ca","metadata":{"id":"be5e67ca"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.preprocessing import image\n","\n","\n","# Loading the saved model\n","loaded_model = tf.keras.models.load_model('trained_model.h5')\n","# cnn_loaded_model = tf.keras.models.load_model('cnn_trained_model.h5')\n","\n","def _get_hashtag(label):\n","    return ','.join([i for i in random.choice(hashtags_mapping[f\"{label}\"])])\n","\n","\n","def get_final_hashtags(img_path):\n","    # Load and preprocess the test image\n","    test_image_path = img_path\n","    test_image = image.load_img(test_image_path, target_size=(img_height, img_width))\n","    test_image = image.img_to_array(test_image)\n","    test_image = np.expand_dims(test_image, axis=0)\n","    test_image /= 255.0\n","    # Make predictions using the CNN model\n","#     cnn_predictions = cnn_loaded_model.predict(test_image)\n","#     cnn_predicted_class = np.argmax(cnn_predictions)\n","#     cnn_class_labels = train_generator.class_indices\n","#     cnn_predicted_label = list(cnn_class_labels.keys())[list(cnn_class_labels.values()).index(cnn_predicted_class)]\n","\n","    # Make predictions using the transfer learning model\n","    transfer_predictions = loaded_model.predict(test_image)\n","    transfer_predicted_class = np.argmax(transfer_predictions)\n","    predicted_probability = transfer_predictions[0][transfer_predicted_class]\n","\n","    if predicted_probability >=.80:\n","        print(f'predicted with confidence {predicted_probability} moving to get hastags genrator')\n","        transfer_class_labels = train_generator.class_indices\n","        transfer_predicted_label = list(transfer_class_labels.keys())[list(transfer_class_labels.values()).index(transfer_predicted_class)]\n","\n","        res = f\"#{transfer_predicted_label},\"+f\"{_get_hashtag(transfer_predicted_label)}\"\n","\n","    else:\n","        print(f'predicted with less confidence {predicted_probability} skipping the hastags genrator')\n","\n","    return res"]},{"cell_type":"code","execution_count":null,"id":"faad0f3f","metadata":{"id":"faad0f3f"},"outputs":[],"source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","img_path = 'sort_sports/rahul_cricket.jpg'\n","test_image = Image.open(img_path)\n","\n","# Display the test image\n","plt.imshow(test_image)\n","plt.axis('off')\n","plt.show()\n","\n","get_final_hashtags(img_path)"]},{"cell_type":"code","execution_count":null,"id":"4a6347ce","metadata":{"id":"4a6347ce"},"outputs":[],"source":["transfer_predictions = loaded_model.predict(test_image)\n","transfer_predicted_class = np.argmax(transfer_predictions)\n","transfer_class_labels = train_generator.class_indices\n","\n","# Get the class label and its corresponding probability\n","predicted_label = list(transfer_class_labels.keys())[transfer_predicted_class]\n","predicted_probability = transfer_predictions[0][transfer_predicted_class]\n","\n","# Show the predicted class label and its confidence score\n","print(f\"Predicted Class: {predicted_label}\")\n","print(f\"Confidence Score: {predicted_probability}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}